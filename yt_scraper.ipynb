{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yt_dlp import YoutubeDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "video_url = \"https://www.youtube.com/watch?v=xy5OQ2IWNtc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=xy5OQ2IWNtc\n",
      "[youtube] xy5OQ2IWNtc: Downloading webpage\n",
      "[youtube] xy5OQ2IWNtc: Downloading ios player API JSON\n",
      "[youtube] xy5OQ2IWNtc: Downloading mweb player API JSON\n",
      "[youtube] xy5OQ2IWNtc: Downloading m3u8 information\n",
      "dict_keys(['id', 'title', 'formats', 'thumbnails', 'thumbnail', 'description', 'channel_id', 'channel_url', 'duration', 'view_count', 'average_rating', 'age_limit', 'webpage_url', 'categories', 'tags', 'playable_in_embed', 'live_status', 'release_timestamp', '_format_sort_fields', 'automatic_captions', 'subtitles', 'comment_count', 'chapters', 'heatmap', 'like_count', 'channel', 'channel_follower_count', 'uploader', 'uploader_id', 'uploader_url', 'upload_date', 'timestamp', 'availability', 'original_url', 'webpage_url_basename', 'webpage_url_domain', 'extractor', 'extractor_key', 'playlist', 'playlist_index', 'display_id', 'fulltitle', 'duration_string', 'release_year', 'is_live', 'was_live', 'requested_subtitles', '_has_drm', 'epoch', 'requested_formats', 'format', 'format_id', 'ext', 'protocol', 'language', 'format_note', 'filesize_approx', 'tbr', 'width', 'height', 'resolution', 'fps', 'dynamic_range', 'vcodec', 'vbr', 'stretched_ratio', 'aspect_ratio', 'acodec', 'abr', 'asr', 'audio_channels'])\n",
      "{'URL': 'https://www.youtube.com/watch?v=xy5OQ2IWNtc', 'Title': 'DataPipeline Tutorial [Ecommerce Scraping Webinar]', 'Width': 1864, 'Height': 1080, 'Language': 'en', 'Channel': 'ScraperAPI', 'Likes': 0}\n"
     ]
    }
   ],
   "source": [
    "opts = dict()\n",
    "\n",
    "info_l = None\n",
    "\n",
    "with YoutubeDL(opts) as yt:\n",
    "    info = yt.extract_info(video_url, download=False)\n",
    "    info_l = info\n",
    "    print(info.keys())\n",
    "    video_title = info.get(\"title\")\n",
    "    width = info.get(\"width\")\n",
    "    height = info.get(\"height\")\n",
    "    language = info.get(\"language\")\n",
    "    channel = info.get(\"channel\")\n",
    "    likes = info.get(\"like_count\")\n",
    "    data = {\"URL\": video_url, \"Title\": video_title, \"Width\": width, \"Height\": height, \"Language\": language, \"Channel\": channel, \"Likes\": likes }\n",
    "    \n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-22 18:23:53\n",
      "2023-12-22 00:00:00\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "timestamp = info_l[\"timestamp\"]\n",
    "date = datetime.fromtimestamp(timestamp)\n",
    "print(date)\n",
    "upload_date = datetime.strptime(info_l['upload_date'], '%Y%m%d')\n",
    "print(upload_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada_epfl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
