{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert json to parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_path = \"yt_metadata_en.jsonl\"\n",
    "\n",
    "chunksize = 1_000_000\n",
    "parquet_file_path = \"yt_metadata_en.parquet\"\n",
    "\n",
    "# Use pandas to read JSON file in chunks\n",
    "for i, chunk in enumerate(pd.read_json(json_file_path, lines=True, chunksize=chunksize)):\n",
    "    print(f\"Processing chunk {i}\")\n",
    "    if i == 0:\n",
    "        chunk.to_parquet(parquet_file_path)\n",
    "    else:\n",
    "        chunk.to_parquet(parquet_file_path, engine=\"fastparquet\", append=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset subsets\n",
    "\n",
    "For easier handling of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sport keyword dataset\n",
    "\n",
    "Do a filtering where we create a dataset subset using sport keywords (e.g. \"football\", \"soccer\", \"basketball\", \"tennis\", etc.) to identify sports-related videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_subset_parquet(parquet_file_path, filter_function, chunksize=1_000_000):\n",
    "    pq_metadata = pq.ParquetFile(parquet_file_path)\n",
    "\n",
    "    # Initialize an empty DataFrame to store the filtered data\n",
    "    filtered_df = pd.DataFrame()\n",
    "\n",
    "    # Iterate through the batches and filter the necessary columns\n",
    "    for batch in pq_metadata.iter_batches(batch_size=chunksize):\n",
    "        temp_df = batch.to_pandas().drop(columns=['description'])\n",
    "        temp_df = temp_df[temp_df.apply(lambda row: filter_function(row), axis=1)]\n",
    "        filtered_df = pd.concat([filtered_df, temp_df], ignore_index=True)\n",
    "\n",
    "        # Print the size and memory usage of the filtered DataFrame\n",
    "        print(f\"Current size of filtered_df: {filtered_df.shape}\")\n",
    "        print(f\"Memory usage of filtered_df: {filtered_df.memory_usage(deep=True).sum() / (1024 ** 2):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_keyword_function(row):\n",
    "    return any(tag in row['tags'].lower() for tag in ['sport', 'football', 'soccer', 'fifa', 'nba', 'olympic', 'golf', 'tennis', 'cricket', 'formula1', 'f1', 'basketball', 'nascar', 'nfl', 'world cup', 'eurocup', 'superbowl']) or any(\n",
    "        tag in row['title'].lower() for tag in ['sport', 'football', 'soccer', 'fifa', 'olympic', 'golf', 'tennis', 'cricket', 'formula1', 'f1', 'basketball', 'nascar', 'nfl', 'world cup', 'eurocup', 'superbowl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_file_path = \"yt_metadata_en.parquet\"\n",
    "\n",
    "pq_metadata = pq.ParquetFile(parquet_file_path)\n",
    " \n",
    "# Initialize an empty DataFrame to store the filtered data\n",
    "filtered_df = pd.DataFrame()\n",
    "\n",
    "# Iterate through the batches and filter the necessary columns\n",
    "for batch in pq_metadata.iter_batches(batch_size=1_000_000):\n",
    "    temp_df = batch.to_pandas().drop(columns=['description'])\n",
    "    temp_df = temp_df[temp_df.apply(lambda row: any(tag in row['tags'].lower() for tag in ['sport', 'football', 'soccer', 'fifa', 'nba', 'olympic', 'golf', 'tennis', 'cricket', 'formula1', 'f1', 'basketball', 'nascar', 'nfl', 'world cup', 'eurocup', 'superbowl']) or any(tag in row['title'].lower() for tag in ['sport', 'football', 'soccer', 'fifa', 'olympic', 'golf', 'tennis', 'cricket', 'formula1', 'f1', 'basketball', 'nascar', 'nfl', 'world cup', 'eurocup', 'superbowl']), axis=1)]\n",
    "    filtered_df = pd.concat([filtered_df, temp_df], ignore_index=True)\n",
    "\n",
    "    # Print the size and memory usage of the filtered DataFrame\n",
    "    print(f\"Current size of filtered_df: {filtered_df.shape}\")\n",
    "    print(f\"Memory usage of filtered_df: {filtered_df.memory_usage(deep=True).sum() / (1024 ** 2):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.to_parquet(\"filtered_sport_metadata(by_tags_and_title)_withoud_description.parquet\", engine=\"fastparquet\")\n",
    "\n",
    "# save the file without the gaming category\n",
    "filtered_df_without_gaming = filtered_df[~filtered_df['category'].str.contains(\n",
    "    'Gaming')]\n",
    "\n",
    "filtered_df_without_gaming.to_parquet(\n",
    "    \"filtered_sport_metadata(by_tags_and_title)_without_gaming_category.parquet\", engine=\"fastparquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sport category dataset\n",
    "\n",
    "Do a filter where we only grab the Sport category from the category column from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_category_function(row):\n",
    "    return \"Sports\" in row['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_file_path = \"yt_metadata_en.parquet\"\n",
    "\n",
    "pq_metadata = pq.ParquetFile(parquet_file_path)\n",
    "\n",
    "# Initialize an empty DataFrame to store the filtered data\n",
    "filtered_sport_df = pd.DataFrame()\n",
    "\n",
    "# Iterate through the batches and filter the necessary columns\n",
    "for batch in pq_metadata.iter_batches(batch_size=1_000_000):\n",
    "    temp_df = batch.to_pandas().drop(columns=['description'])\n",
    "\n",
    "    temp_df = temp_df[temp_df['categories'].apply(lambda x: 'Sports' in x)]\n",
    "    filtered_sport_df = pd.concat(\n",
    "        [filtered_sport_df, temp_df], ignore_index=True)\n",
    "    \n",
    "    # Print the size and memory usage of the filtered DataFrame\n",
    "    print(f\"Current size of filtered_df: {filtered_sport_df.shape}\")\n",
    "    print(f\"Memory usage of filtered_df: {filtered_sport_df.memory_usage(deep=True).sum() / (1024 ** 2):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sport_df.to_parquet(\"filtered_sport_category_without_description_column_metadata.parquet\", engine=\"fastparquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
